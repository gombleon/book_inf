<!DOCTYPE html>
<html>
<meta charset="UTF-8" />
<link rel='stylesheet' type="text/css" href="style.css"></link>
<meta name="author" content="dima" />
<meta name="description" content="Понятие информации" />
<meta name="keywords" content="сообщение, информация, информатика" />
<head><title>Понятие информации</title></head>
<body>
<p><a href="index.html">К содержанию</a> <a href="1_2.html">К следующему</a></p>
<h1>1. Информация</h1> 
<h2>1.1. Понятие информации</h2>
<p>Термин <span class="termin">информатика</span> впервые был введён в Германии Карлом Штейнбухом в 1957 году. В 1962 году этот термин был введён во французский язык Ф. Дрейфусом, который также предложил и переводы на ряд других европейских языков.</p>
<p>В октябре 1962 года член-корреспондент АН СССР А. А. Харкевич рекомендовал этот термин для наименования новой дисциплины, а в 1965 году профессор Я. Г. Дорфман предложил следующее определение:</p>
<p> <span class="teorema">Информатика есть наука о способах получения, накопления, хранения, преобразования, передачи и использования информации.</span></p>
<p>В Германии эту дисциплину называют <span class="termin">&quot;Informatik&quot;</span>, во Франции &#8212; <span class="termin">&quot;Informatique&quot;</span>, в Великобритании &#8212; <span class="termin">&quot;computing science&quot;</span> (вычислительная наука), в США &#8212; <span class="termin">&quot;computer science&quot;</span> (компьютерная наука).</p>
<p>Она включает дисциплины, так или иначе относящиеся к обработке информации в вычислительных машинах и вычислительных сетях: как абстрактные, вроде анализа алгоритмов, так и довольно конкретные, например, разработка языков программирования.</p>
<p>Основополагающим понятием информатики является <span class="termin">информация</span>. В простейшем бытовом понимании с термином информация обычно ассоциируются некоторые сведения, данные, сообщения. Информировать в этом смысле означает сообщить сведения, неизвестные ранее. В технике под информацией понимают сообщения, передаваемые в форме знаков или сигналов; в кибернетике под информацией понимается та часть знаний, которая используется для управления, активного действия, т.е. в целях сохранения, совершенствования, развития системы.</p>
<p>Современное научное представление об информации сформулировал Норберт Винер таким образом:</p>
<cite>"... информация - это обозначение содержания, полученного из внешнего мира в процессе нашего приспособления к нему, и приспособления к нему наших чувств".</cite>
<p>Клод Шеннон, американский ученый, заложивший основы теории информации, рассматривает информацию как содержание сообщения, раскрывающего неопределенности наших знаний о чем-то, следовательно, информация им трактуется как противоположность неопределенности.</p>
<p>Над формулированием понятия информации, определением количества информации бились многие ученые. Попытки количественного измерения информации предпринимались неоднократно. Первые отчетливые предложения об общих способах измерения количества информации были сделаны Рональдом Фишером (1921 г.) в процессе решения вопросов математической статистики. Р. Фишер впервые ввел в математику термин информация, но полученнные им формулы узко специализированы.</p>
<p>Проблемами хранения информации, передачи ее по каналам связи и задачами определения количества информации занимались Р. Хартли (1928 г.) <a href="litra.html#36">[37]</a> и Х. Найквист (1924 г.).</p>
<p>Наиболее убедительно эти вопросы были разработаны и обобщены американским математиком и инженером Клодом Шенноном в 1948 г. в работе &quot;Математическая теория связи&quot; <a href="litra.html#41">[42]</a>. Он выписал формулы для вычисления количества информации и энтропии. Термин <span class="termin">&quot;энтропия&quot;</span> им используется по совету фон Неймана, так как формулы для теории информации совпали с соответствующими формулами статистической физики. В статистическую же физику понятие энтропии было введено в 1865 году немецким физиком Рудольфом Клаузиусом как мера уравношеннности системы.</p>
<p>К середине 50-х годов советский математик А.Н. Колмогоров <a href="litra.html#13">[14]</a> предложил наиболее общее определение количества информации в вероятностном смысле, а в дальнейшем развил и другой подход, так называемую алгоритмическую теорию информации, в котором под энтропией понималась сложность объекта, равная сложности алгоритма, описывающего объект.</p>
<p>Для того, чтобы применить математические методы к изучению информации, в статистическом подходе, в отличие от семантического, потребовалось отвлечься от смысла информации. Этот подход был общим для упомянутых исследователей, так как математика оперирует с количественными соотношениями, не вдаваясь в физическую природу тех объектов, за которыми стоят соотношения.</p>
<p>Информация является категорией нематериальной, и поэтому должна иметь материальный носитель. Материальный объект или среду, которые служат для хранения или передачи информации будем называть ее <span class="termin">материальным носителем</span>.</p>
<p>Хранение информации связано с фиксацией некой характеристики материального носителя, а передача &#8212; с изменением этой характеристики. Например, на лазерном диске информация сохраняется путем фиксации угла отражения луча света от его поверхности. Для передачи информации по телефонной линии используется изменение напряжения электрического поля. В первом случае материальным носителем является лазерный диск, во втором &#8212; электрическое поле.</p>
<p> <span class="teorema"><a name="signal"></a>Изменение характеристики носителя, которое используется для представления информации, называется сигналом, а значение этой характеристики, отнесенное к некоторой шкале измерений, параметром сигнала</span>.</p>
<p>Для передачи информации используют последовательность сигналов, которую называют <span class="termin">сообщением</span>. Сообщение &#8212; материальная оболочка информации. Сообщение передается источником, а принимается &#8212; приемником.</p>
<h3>Контрольные вопросы</h3>
<ol>
<li>Приведите примеры процессов, используемых для передачи информации, и связанных с ними сигналов.</li>
<li>Приведите примеры неоднозначного и однозначного соответствия между сообщением и содержащейся в нем информацией.</li> 
<li>Почему хранение информации нельзя считать информационным процессом?</li>
</ol>
<p><a href="index.html">К содержанию</a> <a href="1_2.html">К следующему</a></p>
</body>
</html>
